## ----------------------------------------- ##

input<- data.frame(test.length = test.length, seasonality = seasonality,
observation.freq = observation.freq, timeformat = timeformat,
makeParallel = makeParallel, horizon=horizon,
stringsAsFactors = FALSE)

# Select data.frame to be sent to the output Dataset port
#maml.mapOutputPort("input");

#1.2
# data input
#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2) # class: data.frame
data <- allData
attach(input)

## ------- User-Defined Parameters ------ ##
min.length <- 2*seasonality
value.threshold <- 20
## ----------------------------------------- ##


# Date format clean-up
data$DATE <- as.POSIXct(as.numeric(as.POSIXct(data$DATE, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")

library(plyr)

# apply business rules
businessrule <- function(data){
tsvalues <- data$NETTO_EUR

# Select Eligible Time Series:
# Rule 1: if a time series has no more than <min.length> non-NA values, discard
if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))

# Rule 2: if a time series has any sales quantity <= value.threshold , discard
#if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))

return(c(judge = 0))
}

judge.all <- ddply(data, .(SITEID, AGRID), businessrule)
judge.good <- judge.all[judge.all$judge == 0, c("SITEID", "AGRID")]
data.good <- join(data, judge.good, by = c("SITEID", "AGRID"), type = "inner")

#maml.mapOutputPort("data.good");

#1.3

# Map 1-based optional input ports to variables
#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2)
#attach(input)

#library(plyr)

data$DATE <- as.Date(data$DATE, format=timeformat)

min.DATE <- min(data$DATE)
max.DATE <- max(data$DATE)

unique.DATE <- seq(from = min.DATE, to = max.DATE, by = observation.freq)

# For every (SITEID, AGRID) pair, create (SITEID, AGRID, DATE) combination
unique.SITEAGRID <- unique(data[, c("SITEID", "AGRID")])
comb.SITEID <- rep(unique.SITEAGRID$SITEID, each = length(unique.DATE))
comb.AGRID <- rep(unique.SITEAGRID$AGRID, each = length(unique.DATE))
comb.DATE <- rep(unique.DATE, times = dim(unique.SITEAGRID)[1])
comb <- data.frame(SITEID = comb.SITEID, AGRID = comb.AGRID, DATE = comb.DATE)

# Join the combination with original data
data <- join(comb, data, by = c("SITEID", "AGRID", "DATE"), type = "left")

# Select data.frame to be sent to the output Dataset port
#maml.mapOutputPort("data");

#1.4

# data input
#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2) # class: data.frame
#attach(input)

# Date format clean-up
data$DATE <- as.POSIXct(as.numeric(as.POSIXct(data$DATE, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")

#library(plyr)

# apply business rules
businessrule2 <- function(data){
# Train and test split
data.length <- dim(data)[1]
train.length <- data.length - test.length

tsvalues <- data$NETTO_EUR

# Select Eligible Time Series based on training and testing principals:
# Rule 3: if the last 6 values in trainning set are all NA, discard
if (sum(is.na(tsvalues[(train.length - 5) : train.length])) == 6) return(c(judge = 3))

# Rule 4: if test data has more than a half NA, discard
if (test.length > 0 && sum(is.na(tsvalues[(train.length+1):data.length])) > test.length / 2) return(c(judge = 4))

return(c(judge = 0))
}

judge.all <- ddply(data, .(SITEID, AGRID), businessrule2, .progress = "win")
judge.good <- judge.all[judge.all$judge == 0, c("SITEID", "AGRID")]
data.good <- join(data, judge.good, by = c("SITEID", "AGRID"), type = "inner")

#maml.mapOutputPort("data.good");
#2.1
# data input
#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2) # class: data.frame
#attach(input)


library(forecast)
library(plyr)
library(parallel)
library(foreach)

data <- data.good
input$makeParallel <- FALSE

# Date format clean-up
data$DATE <- as.POSIXct(as.numeric(as.POSIXct(data$DATE, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")

# Helper functions extracting date-related information
weeknum <- function(date){ date <- as.Date(date, format=timeformat); as.numeric(format(date, "%U"))}
year <- function(date){ date <- as.Date(date, format=timeformat); as.numeric(format(date, "%Y"))}
date.info <- function(df){ date <- df$DATE[1]; c(year(date), weeknum(date))}

# Forecasting set-up
if (!("horizon" %in% colnames(input)) & "test.length" %in% colnames(input)) {print(TRUE); input$horizon <- input$test.length}



# Forecasting Function
stlets.single.id <- function(data){
method.name <- "STL_ETS"

# Train and test split
data.length <- nrow(data)
train.length <- data.length - input$horizon
train <- data[1:train.length, ]
test <- data[(train.length+1):data.length, ]

# Missing data: replace na with average
train$NETTO_EUR[is.na(train$NETTO_EUR)] <- mean(train$NETTO_EUR, na.rm = TRUE)

# Build forecasting models
train.ts <- ts(train$NETTO_EUR, frequency = input$seasonality, start = date.info(train))
train.stl <- stl(train.ts, s.window="periodic")
train.model <- forecast(train.stl, h = input$horizon, method = 'ets', ic = 'bic', opt.crit='mae')

forecast.NETTO_EUR <- train.model$mean
forecast.lo95 <- train.model$lower[,1]
forecast.hi95 <- train.model$upper[,1]

output <- data.frame(DATE = test$DATE, cbind(forecast.NETTO_EUR, forecast.lo95, forecast.hi95))
colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")

return(output)
}



#maml.mapOutputPort("output");

#2.2

# Forecasting Function
snaive.single.id <- function(data){
method.name <- "snaive"

# Train and test split
data.length <- nrow(data)
train.length <- data.length - input$horizon
train <- data[1:train.length, ]
test <- data[(train.length+1):data.length, ]

# Missing data: replace na with average
train$NETTO_EUR[is.na(train$NETTO_EUR)] <- mean(train$NETTO_EUR, na.rm = TRUE)

# Build forecasting models
train.ts <- ts(train$NETTO_EUR, frequency = input$seasonality, start = date.info(train))
train.model <- snaive(train.ts, h = input$horizon)

forecast.NETTO_EUR <- train.model$mean
forecast.lo95 <- train.model$lower[,1]
forecast.hi95 <- train.model$upper[,1]

output <- data.frame(DATE = test$DATE, cbind(forecast.NETTO_EUR, forecast.lo95, forecast.hi95))
colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")

return(output)
}



arima.single.id <- function(data){
method.name <- "STL_ARIMA"

# Train and test split
data.length <- nrow(data)
train.length <- data.length - input$horizon
train <- data[1:train.length, ]
test <- data[(train.length+1):data.length, ]

# Missing data: replace na with average
train$NETTO_EUR[is.na(train$NETTO_EUR)] <- mean(train$NETTO_EUR, na.rm = TRUE)

# Build forecasting models
train.ts <- ts(train$NETTO_EUR, frequency = input$seasonality, start = date.info(train))
train.model <- stlf(train.ts, h = input$horizon, method = "arima", s.window = "periodic")

forecast.NETTO_EUR <- train.model$mean
forecast.lo95 <- train.model$lower[,1]
forecast.hi95 <- train.model$upper[,1]

output <- data.frame(DATE = test$DATE, cbind(forecast.NETTO_EUR, forecast.lo95, forecast.hi95))
colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")

return(output)
}
if(input$makeParallel){
#parallelize
nodes <- detectCores()
cl <- makeCluster(nodes/2)

output1 <- ddply(data, .(SITEID, AGRID), arima.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
output2 <- ddply(data, .(SITEID, AGRID), snaive.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
output3 <- ddply(data, .(SITEID, AGRID), stlets.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))

stopCluster(cl)
}
if(!input$makeParallel){
output1 <- ddply(data, .(SITEID, AGRID), arima.single.id, .progress = "win")
output2 <- ddply(data, .(SITEID, AGRID), snaive.single.id, .progress = "win")
output3 <- ddply(data, .(SITEID, AGRID), stlets.single.id, .progress = "win")
}
output4 <- join(output1, output2, by = c("SITEID", "AGRID", "DATE"), type = "inner")
output <- join(output3, output4, by = c("SITEID", "AGRID", "DATE"), type = "inner")


library(doParallel)
nodes <- detectCores()
cl <- makeCluster(nodes/2)
regisrerCluster(c1)
registerDoParallel()
library(parallel)
library(foreach)
library(doParallel)
library(doParallel)
library(doParallel)
base::detach("package:forecast")
library(doParallel)
library(foreach)
library(doParallel)
install.packages("doParallel")
library(doParallel)
base::library(doParallel)
utils:::menuInstallPkgs()
base::library(doParallel)
library(parallel)
library(foreach)
library(doParallel)
#parallelize

nodes <- detectCores()
cl <- makeCluster(nodes/2)
registerDoParallel()
output1 <- ddply(data, .(SITEID, AGRID), arima.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
library(plyr)
output1 <- ddply(data, .(SITEID, AGRID), arima.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
output1 <- ddply(data, .(SITEID, AGRID), arima.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
output2 <- ddply(data, .(SITEID, AGRID), snaive.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
output3 <- ddply(data, .(SITEID, AGRID), stlets.single.id, .parallel = TRUE, .paropts = list(.packages = "forecast",.export=c("data", "input", "date.info", "weeknum", "year")))
base::local({pkg <- utils::select.list(base::sort(base::.packages(all.available = TRUE))); if(base::nchar(pkg)) base::library(pkg, character.only=TRUE)})
registerDoParallel()
base::local({pkg <- utils::select.list(base::sort(base::.packages(all.available = TRUE))); if(base::nchar(pkg)) base::library(pkg, character.only=TRUE)})
head(data)
install.packages("foreach")
install.packages("doMC")
install.packages("doParallel")
library(doParallel)
install.packages("iterators")
library(doParallel)
library(doParallel)
library(doParallel)
head(data)
head(output)
test.addlags
test
test.addlags
nrow(data)
test  <- data[(train.length+1):data.length, , drop = FALSE]
data.length <- nrow(data)
train.length <- data.length - test.length
test  <- data[(train.length+1):data.length, , drop = FALSE]
len(test)
length(test)
test
train  <- data[1:train.length, , drop = FALSE]
train
test
head(train)
nrow(test)
test
train$NETTO_EUR
# Missing data: replace NA with average
train$NETTO_EUR[is.na(train$NETTO_EUR)] <- mean(train$NETTO_EUR, na.rm = TRUE)

# Create lag features
test$horizon <- as.factor(1:test.length)
test.lags <- data[train.length - lags + 1, var]
test.lags <- data[train.length - lags + 1, "NETTO_EUR"]
test.lags
test.lags <- data[train.length - lags + 1, .(SITEID, AGRID)]
# Map 1-based optional input ports to variables
#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2)
#attach(input)

library(zoo)
library(timeDate)

# Date format clean-up
data$DATE <- as.POSIXct(as.numeric(as.POSIXct(data$DATE, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")

## ----------------------------------------------------------- User-defined Features --------------------------------------------- ##

# Date Features
data$year <- as.numeric(format(data$DATE, "%Y"))
data$month <- as.numeric(format(data$DATE, "%m"))
data$weekofmonth <- ceiling(as.numeric(format(data$DATE, "%d"))/7)

obsdayofweek <- as.numeric(format(data$DATE[1], "%u"))
adjStartofWeek <- 60*60*24*(7-obsdayofweek)
data$weekofyear <- as.numeric(format(data$DATE+adjStartofWeek, "%U"))
data$dayofmonth <- as.numeric(format(data$DATE, "%d"))
data$dayofweek <- as.numeric(format(data$DATE, "%u"))
#data$hourofday <- as.numeric(format(data$DATE, "%H"))

# DATE Features
#data$time_cat <- "Night"
#data$time_cat[data$hourofday>=5 & data$hourofday <=11] <- "Morning"
#data$time_cat[data$hourofday>=12 & data$hourofday <=15] <- "Afternoon"
#data$time_cat[data$hourofday>=16 & data$hourofday <=20] <- "Evening"

# Season Features - American east coast
data$season <-"Winter"
data$season[data$month>=3 & data$month <=5] <- "Spring"
data$season[data$month>=6 & data$month <=8] <- "Summer"
data$season[data$month>=9 & data$month <=11] <- "Fall"

# Weekday-and-weekend Features
data$weekend <-FALSE
data$weekend[data$dayofweek>=6 & data$dayofweek<=7] <- TRUE

# Holiday Features
# These codes only apply to weekly data
CyberMonday <- function(years){as.timeDate(as.Date(USThanksgivingDay(years))+4)}

years = unique(data$year)

adjHolidays <- function(holidays){
holidays <- as.Date(holidays)
hlddayofweek <- as.numeric(format(holidays, "%u"))
return(as.timeDate(holidays + obsdayofweek - hlddayofweek  +7*(hlddayofweek > obsdayofweek)))
}

data.DATE <- as.timeDate(data$DATE)

#data$USNewYearsDay <- isHoliday(data.DATE, holidays = adjHolidays(USNewYearsDay(years)), wday = 0:6)
#data$USLaborDay <- isHoliday(data.DATE, holidays = adjHolidays(USLaborDay(years)), wday = 0:6)
#data$USThanksgivingDay <- isHoliday(data.DATE, holidays = adjHolidays(USThanksgivingDay(years)), wday = 0:6)
#data$CyberMonday <- isHoliday(data.DATE, holidays = adjHolidays(CyberMonday(years)), wday = 0:6)
#data$ChristmasDay <-  isHoliday(data.DATE, holidays = adjHolidays(ChristmasDay(years)), wday=0:6)

# Another way of adding holiday features.
# Applies to daily/hourly data
# data$holiday <- FALSE
# holidays <- c("2013-08-15", "2013-11-30", "2013-12-01", "2014-04-20", "2014-04-21",
#              "2014-05-01", "2014-06-08", "2014-06-09", "2014-08-15", "2014-11-30")
# for (i in 1:length(holidays)){
#   data$holiday[as.Date(data$DATE) == holidays[i]] <- TRUE
# }

# Fourier Features
num.ts <- nrow(unique(data[, c("SITEID", "AGRID")]))
ts.length <- nrow(data)/num.ts
t <- (index(data) - 1) %% ts.length %% seasonality

for (s in 1:4){
data[[paste("FreqCos", toString(s), sep="")]] = cos(t*2*pi*s/seasonality)
data[[paste("FreqSin", toString(s), sep="")]] = sin(t*2*pi*s/seasonality)
}

#3.8
## --------------------------------------------------------------------------------------------------------------------------------- ##

# Select data.frame to be sent to the output Dataset port
#maml.mapOutputPort("data");


#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2)
#attach(input)

## ------- User-Defined Parameters ------ ##
lags <- 1:26
ratio <- 1
## ----------------------------------------- ##

#horizon <- test.length

library(plyr)

shift<-function(lag, x){c(rep(NA, lag), head(x,-lag))}
shift<- Vectorize(shift, vectorize.args = "lag")

addlags_oneh <- function(h, lags, df, var){
res <- shift(lags+h-1, x=df[,var])
colnames(res) <- paste("lag", lags, sep = "")
return(cbind(df,res))
}

addlags <- function(df, var, lags, maxh){
horizons <- 1:maxh
res <- adply(horizons, .margin = 1, .fun = addlags_oneh, lags = lags, df = df, var = var)
res <- rename(res, replace = c("X1" = "horizon"))
res <- res[complete.cases(res), ]
return(res)
}

train.addlags <- function(df, var, lags, maxh){
data.length <- nrow(df)
train.length <- data.length - test.length
train <- df[1:train.length, , drop = FALSE]

res <- addlags(train, var, lags, maxh)
return(res)
}

output <- ddply(data, .variables = .(SITEID, AGRID), .fun = train.addlags, var = "NETTO_EUR", lags = lags, maxh = horizon)

#print(dim(output))
#print(ddply(output, .variables = .(SITEID, AGRID), .fun = nrow))

if(ratio < 1){
downsample <- function(data, ratio){ data[sample(nrow(data), size = ratio*nrow(data)),]}
output <- ddply(output, .variables = .(SITEID, AGRID), .fun = downsample, ratio = ratio)
}

#print(dim(output))
#print(ddply(output, .variables = .(SITEID, AGRID), .fun = nrow))

# Select data.frame to be sent to the output Dataset port
#maml.mapOutputPort("output");

#3.9

#data <- maml.mapInputPort(1) # class: data.frame
#input <- maml.mapInputPort(2)
#attach(input)

## ------- User-Defined Parameters ------ ##
lags <- 1:26
ratio <- 1
## ----------------------------------------- ##

horizon <- test.length

library(plyr)

test.addlags <- function(df, var, lags){
data.length <- nrow(df)
train.length <- data.length - test.length
test  <- df[(train.length+1):data.length, , drop = FALSE]
train  <- df[1:train.length, , drop = FALSE]

# Missing data: replace NA with average
train$NETTO_EUR[is.na(train$NETTO_EUR)] <- mean(train$NETTO_EUR, na.rm = TRUE)

# Create lag features
test$horizon <- as.factor(1:test.length)

test.lags <- df[train.length - lags + 1, var]
test.lags <- matrix(rep(test.lags, test.length), nrow = test.length, byrow = TRUE)
colnames(test.lags) <- paste("lag", lags, sep = "")
res <- cbind(test, test.lags)

return(res)
}

output <- ddply(data, .variables = .(SITEID, AGRID), .fun = test.addlags, var = "NETTO_EUR", lags = lags)
